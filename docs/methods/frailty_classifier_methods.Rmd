---
title: "phenotype_classifier_methods"
author: "Andrew Crane-Droesch"
date: "12/02/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

This document aims to describe the methods used in the Phenotype Classification Project.  Broadly, the aim of the project is to identify actionable aspects of geriatric phenotypes from clinical text, such that a health system could intervene to prevent unwanted hospitalizations.  To clarify terms:

- A **phenotype** is a manifestation of some condition or set of conditions.  Examples include "frailty" or "depression".  We're abstracting away from questions about underlying causes of the manifestation, the underlying set of conditions, or even the precise definition.  Rather we're treating it as an emergent property, to be defined operationally from clinical text via an annotation guide (more on the annotation guide below).

- An **aspect** of a phenotype is some sub-condition of the phenotype.  The aggregations of the aspects define the phenotype.  For example, `dyspnea` and `being a fall risk` are both aspects of `frailty`.  A phenotype then is a condition defined by the presence of many aspects of itself.

- An **actionable** aspect is one where a health system could undertake some action to mitigate adverse consequences of an aspect.  For example, grab bars could be installed in bathrooms of people who are identified as being fall risks.

The project's workflow is detailed below.  The following is an overview:

1. Extraction of clinical text based on a population definition
    - Initial development of rule-based sampling criteria
2. Annotation and modelling loop
    a. Notes sampled based on sampling criteria
    b. Development and/or editing of annotation guide
    c. Annotation 
    d. Modeling -- word/span level
    e. Aggregation to document
    f. Prediction
    g. IF it is decided that we have not yet annotated enough:
        - Update sampling criteria, proceed to (a)
        
        ELSE
        - Finish
3. Based on trained model, identify patients with actionable aspects of phenotype.  
  
  
### Note in notation

Below where I use math, lowercase italics indicate a random variable ($x$), uppercase italics indicate a column vector ($X$), bolded lowercase indicates a row vector ($\mathbf{x}$), and uppercase bold indicates a matrix ($\mathbf{X}$).  Greek letters are always parameters, never data.  Calligraphy letters ($\mathcal{X}$) indicate functions.

## 1. Population definition

### Frailty phenotype

We're interested in patients with lung disease, and who are "plugged-in" to Penn Medicine.  Specifically, we're interested in capturing notes corresponding to encounters in which 

- lung disease is included among the patient's diagnoses, and for 
- patients who have at least two outpatient encounters within the past 12 months.

"Lung disease" is operationally defined for our purposes by the following ICD codes:

- J44.[0,1,9]
- J43.[0,1,2,8,9]
- J41.[0,1,8]
- J42
- J84.10
- D86
- J84
- M34.81
- J99.[0,1]

This is operationalized using the following 

```{sql, eval=FALSE}
select e.PAT_ENC_CSN_ID,
  mrn.IDENTITY_ID,
  mrn.PAT_ID,
  icd10.CODE,
  CE.DX_NAME,
  e.ENTRY_TIME,
  e.EFFECTIVE_DATE_DTTM,
  'PAT_ENC_DX' as SOURCE
from PAT_ENC_DX as PED
  inner join PAT_ENC as e on e.PAT_ENC_CSN_ID = PED.PAT_ENC_CSN_ID
  inner join CLARITY_EDG as CE on PED.DX_ID = CE.DX_ID
  inner join EDG_CURRENT_ICD10 as icd10 on icd10.DX_ID = CE.DX_ID
  inner join IDENTITY_ID as mrn on mrn.PAT_ID = e.PAT_ID and mrn.IDENTITY_TYPE_ID = 100
where icd10.CODE is not null and e.ENTRY_TIME > '2017-01-01' and
  (icd10.CODE like '%J44%' or icd10.CODE like '%J43%' or icd10.CODE like '%J41%' or icd10.CODE like '%J42%' or icd10.CODE like '%J84%' or icd10.CODE like '%D86%' or icd10.CODE like '%J84%' or icd10.CODE like '%M34%' or icd10.CODE like '%J99%')

union

select
  e.PAT_ENC_CSN_ID,
  mrn.IDENTITY_ID,
  mrn.PAT_ID,
  icd10.CODE,
  CE.DX_NAME,
  e.ENTRY_TIME,
  e.EFFECTIVE_DATE_DTTM,
  'HSP_ACCT_DX_LIST' as SOURCE
from HSP_ACCT_DX_LIST as PED
  left join CLARITY_EDG as CE on PED.DX_ID = CE.DX_ID
  left join ZC_DX_CC_HA as z1 on z1.DX_CC_HA_C = ped.DX_COMORBIDITY_C
  left join ZC_DX_POA as z2 on z2.DX_POA_C = ped.FINAL_DX_POA_C
  inner join EDG_CURRENT_ICD10 icd10 on icd10.DX_ID = CE.DX_ID
  left join PAT_ENC as e on e.HSP_ACCOUNT_ID = ped.HSP_ACCOUNT_ID
  left join IDENTITY_ID as mrn on mrn.PAT_ID = e.PAT_ID and mrn.IDENTITY_TYPE_ID = 100
where
  icd10.CODE is not null and e.ENTRY_TIME > '2017-01-01' and
  (icd10.CODE like '%J44%' or icd10.CODE like '%J43%' or icd10.CODE like '%J41%' or icd10.CODE like '%J42%' or icd10.CODE like '%J84%' or icd10.CODE like '%D86%' or icd10.CODE like '%J84%' or icd10.CODE like '%M34%' or icd10.CODE like '%J99%')

union

select
  e.PAT_ENC_CSN_ID,
  mrn.IDENTITY_ID,
  mrn.PAT_ID,
  icd10.CODE,
  edg.DX_NAME,
  e.ENTRY_TIME,
  e.EFFECTIVE_DATE_DTTM,
  'PROBLEM_LIST' as SOURCE
from
  PAT_ENC as e
inner join PROBLEM_LIST_HX as ph on ph.HX_PROBLEM_EPT_CSN = e.PAT_ENC_CSN_ID
inner join CLARITY_EDG as edg on edg.DX_ID = ph.HX_PROBLEM_ID
inner join EDG_CURRENT_ICD10 as icd10 on icd10.DX_ID = edg.DX_ID
left join ZC_DX_POA as z1 on z1.DX_POA_C = ph.HX_PROBLEM_POA_C
left join IDENTITY_ID as mrn on mrn.PAT_ID = e.PAT_ID and mrn.IDENTITY_TYPE_ID = 100

where
  icd10.CODE is not null and e.ENTRY_TIME > '2017-01-01' and
  (icd10.CODE like '%J44%' or icd10.CODE like '%J43%' or icd10.CODE like '%J41%' or icd10.CODE like '%J42%' or icd10.CODE like '%J84%' or icd10.CODE like '%D86%' or icd10.CODE like '%J84%' or icd10.CODE like '%M34%' or icd10.CODE like '%J99%')
```

This unites three tables in clarity, each of which contain diagnoses -- `PAT_ENC_DX`, `HSP_ACCT_DX_LIST`, and `PROBLEM_LIST`.  The most important outputs are the encounter unique identifier (`PAT_ENC_CSN_ID`), the patient ID (`PAT_ID`), and the diagnosis code (`CODE`).

The output is further refined in python using the following 
```{python, eval = FALSE}
chronic_regex = '^(J44\.[0,1,9]|J43\.[0,1,2,8,9]|J41\.[0,1,8]|J42|J84\.10|D86|J84|M34\.81|J99\.[0,1])'
diagnosis_df = diagnosis_df[diagnosis_df['CODE'].str.contains(chronic_regex)]
```

The output of this file then provides a list of all patients (via `PAT_ID`) who have ever had these diagnoses.  We want the subset of these patients who have had two outpatient encounters in the previous year.  Note that the previous outpatient encounters need not necessarily be associated with any of the specified lung diseases.  The following query pulls those encounters, along with demographic information.  It restricts encounters to certain specialties deemed relevant to our specific purpose, and only lists encounters that are typed "office visit" or "appointment".  Note that the python script that executes this query subs out the string `:ids` for a list of actual patient ID numbers, so that only the relevant patient IDs are pulled.

```{sql, eval = FALSE}
select e.PAT_ENC_CSN_ID
     , mrn.IDENTITY_ID MRN
     , mrn.PAT_ID
     , e.EFFECTIVE_DATE_DTTM
     , e.ENTRY_TIME
     , datediff(day, pat.BIRTH_DATE, e.ENTRY_TIME) / 365.0      AGE
     , ZHAT.NAME as ADMSN_TYPE
     , zpc.NAME as PATIENT_CLASS
     , dep.DEPT_ABBREVIATION as UNIT
     , dep.DEPARTMENT_NAME
     , dep.EXTERNAL_NAME
     , dep.SPECIALTY
     , CL.LOCATION_ABBR
     , zs.NAME as SEX
     , zm.NAME as MARITAL_STATUS
     , zr.NAME as RELIGION
     , zes.NAME as EMPY_STAT
     , zpr.NAME as RACE
     , ze.NAME as ETHNICITY
     , zl.NAME as LANGUAGE
     , zc.NAME as COUNTY
     , pat.ZIP
     , ZDET.NAME    as  ENCOUNTER_TYPE
from PAT_ENC as e
  left join PAT_ENC_2 as e2 on e2.PAT_ENC_CSN_ID = e.PAT_ENC_CSN_ID
       left join PAT_ENC_HSP as hsp on hsp.PAT_ENC_CSN_ID = e.PAT_ENC_CSN_ID
       inner join PATIENT as pat on pat.PAT_ID = e.PAT_ID
       left join ZC_PAT_CLASS as zpc on e2.ADT_PAT_CLASS_C = zpc.ADT_PAT_CLASS_C
       left join ZC_HOSP_ADMSN_TYPE as ZHAT on e.HOSP_ADMSN_TYPE_C = ZHAT.HOSP_ADMSN_TYPE_C
       left join ZC_PAT_STATUS as zps on hsp.ADT_PATIENT_STAT_C = zps.ADT_PATIENT_STAT_C
       left join CLARITY_DEP as dep on dep.DEPARTMENT_ID = e.DEPARTMENT_ID
       left join CLARITY_LOC as CL on dep.REV_LOC_ID = CL.LOC_ID
       left join ZC_SEX as zs on pat.SEX_C = zs.RCPT_MEM_SEX_C
       left join ZC_ETHNIC_GROUP as ze on pat.ETHNIC_GROUP_C = ze.ETHNIC_GROUP_C
       left join ZC_MARITAL_STATUS as zm on pat.MARITAL_STATUS_C = zm.MARITAL_STATUS_C
       left join ZC_RELIGION as zr on pat.RELIGION_C = zr.RELIGION_C
       left join ZC_LANGUAGE as zl on pat.LANGUAGE_C = zl.LANGUAGE_C
       left join ZC_FIN_CLASS as zf on pat.DEF_FIN_CLASS_C = zf.FIN_CLASS_C
       left join ZC_VETERAN_STAT as zv on pat.VETERAN_STATUS_C = zv.VETERAN_STATUS_C
       left join ZC_EMPY_STAT as zes on pat.EMPY_STATUS_C = zes.EMPY_STAT_C
       left join ZC_COUNTY as zc on pat.COUNTY_C = zc.COUNTY_C
       left join PATIENT_RACE as pr on pr.PAT_ID = e.PAT_ID and pr.LINE = 1
       left join ZC_PATIENT_RACE as zpr on pr.PATIENT_RACE_C = zpr.PATIENT_RACE_C
       inner join IDENTITY_ID as mrn on mrn.PAT_ID = e.PAT_ID and mrn.IDENTITY_TYPE_ID = 100
       left join ZC_DISP_ENC_TYPE as ZDET on e.ENC_TYPE_C = ZDET.DISP_ENC_TYPE_C
where e.ENTRY_TIME >= '2017-01-01'
and dep.SPECIALTY in ('INTERNAL MEDICINE', 'PULMONARY', 'FAMILY PRACTICE', 'GERONTOLOGY')
and ZDET.NAME in ('Appointment', 'Office Visit')
and e.ENTRY_TIME >= '2017-01-01'
and mrn.PAT_ID in :ids
```

The output of the above becomes a data frame, `op_encounters_df`.  This is filtered to ensure that it becomes only the people who have two outpatient encounters withing the past 12 months using the following code.  

First, it is sorted by patient ID and then entry time:

```{python, eval = FALSE}
op_encounters_df = op_encounters_df.sort_values(["PAT_ID", "ENTRY_TIME"])
```
Then, I remove all entries $i$ where entry $i-2$ does not have the same patient ID (i.e.: is not the same person), or where the time stamps are more than one year apart:
```{python, eval = FALSE}
# two conditions:
same_patient_conditon = (op_encounters_df.PAT_ID.shift(periods=2) == op_encounters_df.PAT_ID).astype(int)
time_conditon = ((op_encounters_df.ENTRY_TIME - op_encounters_df.ENTRY_TIME.shift(periods=2)). \
                 dt.total_seconds() / 60 / 60 / 24 / 365 < 1).astype(int)
# unify them
condition = same_patient_conditon * time_conditon
op_encounters_df = op_encounters_df.loc[condition == 1]
```

This contains all encounters for which we should pull notes.  The following query does so, restricting notes to type 19 "progress notes" and status 2 "signed notes."

```{sql, eval = FALSE}
select hi.PAT_ENC_CSN_ID,
       nei.CONTACT_SERIAL_NUM                                    NOTE_SERIAL_NUM,
       ZC_NOTE_TYPE_IP.NAME                                      IP_NOTE_TYPE, 
       COALESCE(nei.ENTRY_INSTANT_DTTM, nei.NOTE_FILE_TIME_DTTM) NOTE_ENTRY_TIME,
       hi.NOTE_ID,
       t.LINE                                                    NOTE_LINE,
       nei.CONTACT_NUM,
       t.NOTE_TEXT
from NOTE_ENC_INFO as nei
  inner join HNO_INFO as hi
    on nei.NOTE_ID = hi.NOTE_ID 
    and 19 = hi.note_type_noadd_c
    and hi.PAT_ENC_CSN_ID in :ids
  inner join ZC_NOTE_TYPE_IP
    on hi.IP_NOTE_TYPE_C = ZC_NOTE_TYPE_IP.TYPE_IP_C 
  inner join HNO_NOTE_TEXT as t
    on nei.CONTACT_SERIAL_NUM = t.NOTE_CSN_ID
    and t.NOTE_TEXT <> ''
where 2 = nei.note_status_c
```

The raw output of this is a data frame of note lines, which are then merged into complete notes in python.

### Initial rule-based sampling

We require an initial set of notes to annotate.  Rather than sampling randomly, we'll choose an initial 100 notes based on a set of rules that are designed as a first pass at classifying a given aspect of a phenotype.  We then apply the rules to all of the notes, and sample randomly from them to yield 50 notes that have are considered to be low probability for containing text relevant to that aspect, and 50 notes that are considered high probability for containing text relevant to that aspect.  

#### Frailty phenotype

We begin with the frailty phenotype.  Note that the initial rule-based sampling will aim to find notes corresponding to patients that are frail or not frail.  This is less specific than any of the aspects of frailty, for which we will be annotating.  We will not annotate for the phenotype itself, rather we will annotate for it's aspects.

The criteria for "high probability" of frailty are:

- 15 or more comorbidities diagnosed within the past 12 months.  
- The note contains any of the following words: 'PO intake', 'weight loss', 'appetite', 'frail', 'frailty', 'weakness', 'feels weak', 'unsteady', 'recent fall', 'getting around', 'severe dyspnea', 'functional impairment', 'difficulty walking', 'difficulty breathing', 'getting in the way', 'exercise', 'Breathless', 'short of breath', 'wheezing', 'delirium', 'dementia', 'incontinence', 'do not resuscitate', 'walker', 'wheelchair', 'malnutrition', 'boost'

The criteria for "low probability" of frailty are:

- 5 or fewer comorbidities diagnosed within the past 12 months
- The note contains any of the following words:  'gym', 'exercise', 'breathing', 'appetite', 'eating', 'getting around', 'functional status', 'PO intake', 'getting around', 'walking', 'running', 'independent'

## 2.  Annotation and modelling loop

This phase of the project operates as a loop.  Each of the steps from the pulling of notes to the updating of the sampling criteria is completed in succession until the models are adequately trained.

### a. Sampling notes based on criteria

During the first pass of this loop, the notes will be sampled based on the deterministic rules described above.  During subsequent passes, the sampling will be based on criteria developed at the end of the loop.

Based on the criteria, some number of notes will be pulled from the population for annotation.  We'll refer to one pull based on one iteration of the loop as one "batch."

### b. Development and/or editing of annotation guide 
### c. Annotation 
### d. Modeling -- word/span level

The output of step c is annotated text, with the annotations at the span level.  Given that spans are comprised of words, we'll associate each word in a span with a span-level annotation.  For example:

> This is so<span style="color:red">me text that I</span> wrote as an example

would be represented as 

```{r, echo=FALSE}
txt = "This is some text that I wrote as an example"
data.frame(word = strsplit(txt, " ")[[1]], label = c(0,0,1,1,1,1,0,0,0,0))
```

The text would then be tokenized, and the labels associated with the subsequent tokens.  Note that we have elected to associate the label with partial spans.  

An effective model must be able to ingest new text and probablistically associate tokens within that text with the label.  The label vector can be directly ingested by a computer, but the word vector cannot, until it is represented numerically.  A simple way of doing so is dummy-coding or "one-hot encoding":

```{r, echo=FALSE}
txt = "This is some text that I wrote as an example"
df = data.frame(word = strsplit(txt, " ")[[1]], label = c(0,0,1,1,1,1,0,0,0,0))
mm = model.matrix(~. - 1, data = df)
dum_df <- as.data.frame(mm)
colnames(dum_df) <- gsub("word", "", colnames(dum_df))
dum_df[,c("label", strsplit(txt, " ")[[1]])]

```

Hereafter we'll refer to the label vector as $Y$ and the dummy matrix as $\mathbf{D}$.  The label vector is a $N \times c$ matrix when there are more than two categories, in which case the vector is bolded to indicate the matrix $\mathbf{Y}$.  The dummy matrix Has dimension $N \times v$, where $v$ is the number of unique words in the corpus.  The dimension of $\mathbf{D}$ could be further shrunk if some words were omitted after weighting via tf-idf or some other weighting scheme.

Ultimately, models that we fit to associate words with labels will be versions of $\mathbf{Y} = \mathcal{F}\left(\mathbf{D}\right) + \epsilon$.  The remainder of this section discusses how we'll specify $\mathcal{F}$.

#### Preprocessing

We'll define some terms before diving into specific approaches.

First, define $\mathbf{X}$ as a given model's design matrix and define the transformation $\mathcal{H}$ as
$$
\mathbf{X} = \mathcal{H}\left(\mathbf{D}\right)
$$
$\mathcal{H}$ is very general, and includes embedding, lags/leads, etc.  $\mathcal{H}$ is also deterministic, in order to distinguish it from $\mathcal{M}$, a statistical model.  We have that $\mathcal{F}(\mathbf{D}) \equiv \mathcal{M}\left(\mathcal{H}(\mathbf{D})\right)$.  If embeddings are generated or modified in the process of training a classifier, then they'd be part of $\mathcal{M}$, rather than $\mathcal{H}$.

##### Embeddings

In general, an embedding model creates the transformation

$$
\mathbf{E} = \mathcal{G}\left(\mathbf{V}\right)
$$
where $\mathbf{V}$ is a square matrix of dimension $v \times v$ and $\mathbf{E}$ has the dimension $v\times u$, where $u<v$.  "Good" embeddings choose transformations $\mathcal{G}$ that minimally discard information which maximally reducing $u$ below $v$.  

For word2vec, $\mathcal{G}$ takes the following form:
$$
\mathbf{E} = \mathbf{V}\Gamma_1
$$
where $\Gamma_1$ is a $v \times u$ matrix.  It is chosen by fitting the model
$$
\mathbf{V}_o = s(\mathbf{V}_i\Gamma_1\Gamma_2)
$$
to minimize some loss function.  $\Gamma_2$ is a $u\times v$ matrix and $s$ is a softmax function.  The subscripts $o$ and $i$ indicate transformations to the diagonal vocabulary matrix to generate CBOW and skip-gram architectures.

Other word embedding models, such as `fasttext` and `glove`, also produce an embedding $\mathbf{E}$, though they aren't as simple to write in matrix equations.

The embeddings are of dimension $v \times u$.  To use them to transform raw input text, simply take the dot product $\mathbf{DE}$.

##### Lags and leads

To lag a vector $X$ $i$ times, simply shift its index by $i$.  Positive lags for the first entry are undefined, which can be handled by zero-padding the vector, or dropping the first $i$ entries.  The former is probably better for our purposes.

##### Window statistics

For a given index range of the rows $i = 1:I$ and columns $j = 1:J$ of $\mathbf{X}$, various window functions $w()$ can be applied in a rolling fashion, yielding one or more columns to be appended to $\mathbf{X}$.  

Examples of window functions:

- Min
- Max
- Mean
- Count

Examples of windows of the index:

- Lag
- Lead
- Centered window
- Present sentence
- Present paragraph
- Lagged/led sentences or paragraphs
- Dilated convolution

Examples of column aggregations

- Identity (i.e.: for $\mathbf{A} = w(\mathbf{B})$, the rank of $\mathbf{A}$ and $\mathbf{B}$ are equal)
- Column-wise min, max, mean, or SD, etc
- PCA, with fewer than $rank\mathbf{(B)}$ components retained.

#### Classifiers

Classifiers are statistical models $\mathcal{M}$ mapping $\mathbf{Y}$ to $\mathbf{X}$.  They are not directly dependent on data transformations $\mathbf{H}$, though some transformations will be better for some models than others.

Examples include:

- Logistic regression (where $\mathbf{X}$ is full rank only)
- Penalized logistic regression
- Random forests
- XGboost
- SVM
- etc

Besides standard multinomial logit, these models all have fairly few hyperparameters, which can be tuned either through gridsearch or some sort of SARSA algorithm.

#### Neural nets

Neural nets are essentially penalized nonlinear logistic regression, solved through gradient descent.  Their basic form in the recurrent case is 

$$
\mathbf{y}_t = a\left(\mathbf{X}_t\Gamma_t + \mathbf{S_{t}}\Gamma_L\right)\\
\mathbf{S}_{t} = \mathbf{X}_{t-1}\Gamma_t + \mathbf{S_{t-1}}\Gamma_L
$$

LSTMs and other variants are similar in principal, but have more complicated architectures.  Bidirectionality is simply the concatenation of two networks that move in opposite directions, before the softmax.

Temporal convolutional networks use 1-dimensional convolutions to achieve much the same thing as LSTMs.

NNs are solved with gradient descent.  This provides an opportunity to embed a set of word2vec weights (call them $\Xi$ instead of $\Gamma_1$ from above), as follows:

$$
\mathbf{y}_t = a\left(b(\mathbf{D\Xi})_t\Gamma_t + \mathbf{S_{t}}\Gamma_L\right)\\
\mathbf{S}_{t} = b(\mathbf{D\Xi})_{t-1}\Gamma_t + \mathbf{S_{t-1}}\Gamma_L
$$
where $b()$ is some differentiable and nonlinear activation function.  Initializing $\Xi$ at `word2vec`'s solution means that the algorithm isn't forced to identify a good low-dimensional representation at the same time as it is trying to find a mapping from the raw data to the model.  But, if the embeddings are not specifically fit to purpose, the algorithm could tweak them at the same time as it tweaks the rest of the model's parameters.

#### Training/testing/prediction

There will be many combinations of $\mathcal{H}$ and model $\mathcal{M}$ that could be tried.  The number increases exponentially when it is considered that most models have many hyperparameters.  

Notes from 2018 will be used as the training set, with $K$-fold cross-validation used to choose hyperparameters.  Folds will be chosen by randomly sampling unique patient IDs, in order to train models to predict for entirely new sets of individuals.  

Skill will be assessed in terms of mean squared percentage (probability) error.  For models that are not well-calibrated (tree-based methods, SVM), Platt Scaling will be performed.  Platt Scaling simply fits a binomial GLM (or GAM) to the score of a fitted classifier, returning a probability from the value of the link function.

### e. Aggregation to document

Each word in the document will be assigned a probability over each label.  Ultimately however, we seek to classify notes (and thereby patients), rather than words.  A simple approach to doing so could be the probability that there is at least one positive label in the document:

$$
  pr(label) = 1-\displaystyle\prod_i \left(1- \hat{y}_i\right)
$$

This framework suggests a way to jointly model structured and text data, by fitting models of the form:

$$
pr(label) = \mathcal{M}\left(\mathbf{Z}, T\right)
$$
where $\mathbf{Z}$ is patient-level structured data and $T \equiv 1-\displaystyle\prod_i \left(1- \hat{y}_i\right)$.  If $\mathcal{M}$ is a neural network (or other differentiable function with parameters chosen by gradient descent), then the sequence model fit to the textual data could be trained conditional upon (and simultaneously with) the structured data.  

Otherwise, the text model could be fit first, and could serve as input to the combined model.

### f. Prediction

Once models are trained, they'll be assessed for skill against the 2019 test set.  The best-performing model will then be applied to the unlabeled data to chooses cases for subsequent annotation.  Approaches for ranking options to choose next include uncertainty sampling, as well as explicit modeling of variance reduction per Unger et al. (2007).  Given a ranking approach, the next 100 notes will be sampled from the unlabeled portion of the training set to form the a new batch.


### g.  Establishing "doneness" criteria

## 3.  Modeling hospitalization risk 

The ultimate goal of this project is to identify patients who are likely to be hospitalized, but whose hospitalization could be prevented by acting upon one of the identified actionable aspects of frailty.  

As such, the purpose of the previous steps has been to identify a population for the purpose of predicatively modeling hospitalization.  Any classifier could be used for this purpose, and the choice between classifiers is a standard model selection problem.

### Comparative efficacy

Given a population of patients with a particular actionable aspect of a phenotype, a hospitalization risk $R \in [0,1]$, and some intervention $d \in \{0,1\}$, it becomes reasonable to ask which patients to intervene upon (i.e.: to cause $d$ to become 1).  Presumably those with positive expected benefit should be intervened-upon, and those with the largest expected benefit should be intervened-upon first  Expected benefit is comprised of individual-level risk of hospitalization, as well as the effect of $d$, which we denote $\tau$.  The average value of $\tau$ can be computed simply via the OLS regression

$$
H_{it} = \alpha_i + \tau d_{it} + [R, \mathbf{X}]_{it}\beta + \epsilon_{it}
$$
where $H$ is actual hospitalization and $X$ are any controls available (for time, etc).  Since $d$ is selected based on $R$, $R$ must be included in the regression to control for its selection effect.  (NB:  patients who independently "self-treat" should be excluded from any such analysis, because we're unable to model their selection mechanism.)  

$\tau$ is an average treatment effect.  Presumably however, the ATE is simply an expectation over a distribution of heterogeneous treatment effects.  In truth, there is an unobservable counterfacutal outcome for every patient in the system.  This can be locally approximated based on available data $\mathbf{X}$ as 

$$
\tau(\mathbf{x}_i) = \left(E[H^{d = 1}] - E[H^{d = 0}]\right)  \big|  \mathbf{X = x}_i
$$
This is estimable *conditional on $R$ and whatever other controls* using algorithms such as the causal forest of Wager and Athey.  

Once we reach the stage of intervening, we can apply a SARSA-like algorithm using this model as the reward function to decide the order in which patients are intervened-upon.  This would enable the health system to proactively learn *both* which patients are likely hospitalization risks, and which patients are the most effectively "helpable" through targeted action.  

